{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b0f28f2b",
   "metadata": {},
   "source": [
    "## Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "046bbc29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Device = mps\n"
     ]
    }
   ],
   "source": [
    "import os, json, random, csv, platform\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch, torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, models\n",
    "from datasets import load_dataset\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support, roc_auc_score, confusion_matrix\n",
    "from tqdm import tqdm\n",
    "\n",
    "SEED = 114514\n",
    "random.seed(SEED); np.random.seed(SEED); torch.manual_seed(SEED)\n",
    "\n",
    "os.environ.setdefault(\"PYTORCH_ENABLE_MPS_FALLBACK\", \"1\")\n",
    "DEVICE = (\"mps\" if torch.backends.mps.is_available()\n",
    "          else \"cuda\" if torch.cuda.is_available()\n",
    "          else \"cpu\")\n",
    "print(f\"[INFO] Device = {DEVICE}\")\n",
    "\n",
    "OUT = Path(\"outputs/baseline\"); OUT.mkdir(parents=True, exist_ok=True)\n",
    "OUT_EDA = Path(\"outputs/eda\"); OUT_EDA.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "with open(OUT/\"run_info.json\",\"w\") as f:\n",
    "    json.dump({\"seed\": SEED, \"device\": DEVICE,\n",
    "               \"python\": f\"{os.sys.version_info.major}.{os.sys.version_info.minor}.{os.sys.version_info.micro}\",\n",
    "               \"torch\": torch.__version__}, f, indent=2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31fb59ed",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "2227a7bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['image', 'label'],\n",
       "        num_rows: 4187\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['image', 'label'],\n",
       "        num_rows: 1045\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['image', 'label'],\n",
       "        num_rows: 624\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds = load_dataset(\"mmenendezg/pneumonia_x_ray\")  # splits: train/validation/test\n",
    "ds\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92456104",
   "metadata": {},
   "source": [
    "## EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "31b5f062",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train': {'n': 4187,\n",
       "  'class_count': {0: 1080, 1: 3107},\n",
       "  'size_sample_mean': [500.0, 500.0],\n",
       "  'size_sample_min': [500, 500],\n",
       "  'size_sample_max': [500, 500]},\n",
       " 'validation': {'n': 1045,\n",
       "  'class_count': {0: 269, 1: 776},\n",
       "  'size_sample_mean': [500.0, 500.0],\n",
       "  'size_sample_min': [500, 500],\n",
       "  'size_sample_max': [500, 500]},\n",
       " 'test': {'n': 624,\n",
       "  'class_count': {0: 234, 1: 390},\n",
       "  'size_sample_mean': [500.0, 500.0],\n",
       "  'size_sample_min': [500, 500],\n",
       "  'size_sample_max': [500, 500]}}"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def split_stats(split, sample_k=200, seed=SEED):\n",
    "    n = len(split)\n",
    "    labels = np.array(split[\"label\"], dtype=int)\n",
    "    cnt = np.bincount(labels, minlength=2)\n",
    "    k = min(sample_k, n)\n",
    "    rng = random.Random(seed)\n",
    "    idx = rng.sample(range(n), k) if n > 0 else []\n",
    "    w_list, h_list = [], []\n",
    "    for i in idx:\n",
    "        w, h = split[i][\"image\"].size\n",
    "        w_list.append(w); h_list.append(h)\n",
    "    if k == 0:\n",
    "        size_mean = [0.0, 0.0]; size_min = [0,0]; size_max=[0,0]\n",
    "    else:\n",
    "        size_mean = [float(np.mean(w_list)), float(np.mean(h_list))]\n",
    "        size_min  = [int(np.min(w_list)),   int(np.min(h_list))]\n",
    "        size_max  = [int(np.max(w_list)),   int(np.max(h_list))]\n",
    "    return {\"n\": int(n),\n",
    "            \"class_count\": {0:int(cnt[0]), 1:int(cnt[1])},\n",
    "            \"size_sample_mean\": size_mean,\n",
    "            \"size_sample_min\":  size_min,\n",
    "            \"size_sample_max\":  size_max}\n",
    "\n",
    "stats = {\"train\": split_stats(ds[\"train\"]),\n",
    "         \"validation\": split_stats(ds[\"validation\"]),\n",
    "         \"test\": split_stats(ds[\"test\"])}\n",
    "\n",
    "with open(OUT_EDA/\"data_stats.json\",\"w\") as f:\n",
    "    json.dump(stats, f, indent=2)\n",
    "stats\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad0ab952",
   "metadata": {},
   "source": [
    "## EDA Show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "c59a19b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_class_bar(stats, title=\"Class Distribution (0=normal, 1=pneumonia)\",\n",
    "                   savepath=OUT_EDA/\"class_dist.png\", log_y=False):\n",
    "    savepath = Path(savepath); savepath.parent.mkdir(parents=True, exist_ok=True)\n",
    "    labels = [\"normal(0)\", \"pneumonia(1)\"]\n",
    "    def counts_of(s): d=s[\"class_count\"]; return [int(d.get(0,0)), int(d.get(1,0))]\n",
    "    train_cnt = counts_of(stats[\"train\"]); val_cnt = counts_of(stats[\"validation\"]); test_cnt = counts_of(stats[\"test\"])\n",
    "    x=np.arange(2); w=0.25\n",
    "    fig, ax = plt.subplots(figsize=(7,4.2))\n",
    "    b1=ax.bar(x-w, train_cnt, width=w, label=\"train\")\n",
    "    b2=ax.bar(x,   val_cnt,   width=w, label=\"val\")\n",
    "    b3=ax.bar(x+w, test_cnt,  width=w, label=\"test\")\n",
    "    ax.set_xticks(x); ax.set_xticklabels(labels); ax.set_ylabel(\"count\"); ax.set_title(title)\n",
    "    if log_y: ax.set_yscale(\"log\")\n",
    "    ax.legend()\n",
    "    for bars in (b1,b2,b3):\n",
    "        for rect in bars:\n",
    "            h=rect.get_height()\n",
    "            ax.annotate(f\"{int(h)}\", (rect.get_x()+rect.get_width()/2, h),\n",
    "                        xytext=(0,3), textcoords=\"offset points\",\n",
    "                        ha=\"center\", va=\"bottom\", fontsize=8)\n",
    "    fig.tight_layout(); fig.savefig(savepath, dpi=220); plt.close(fig)\n",
    "    return savepath\n",
    "\n",
    "_ = plot_class_bar(stats)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "048505f8",
   "metadata": {},
   "source": [
    "## Trun in Dataswt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "aef9f4c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGENET_MEAN=[0.485,0.456,0.406]; IMAGENET_STD=[0.229,0.224,0.225]\n",
    "tx_train = transforms.Compose([\n",
    "    transforms.Resize((224,224)),\n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(IMAGENET_MEAN, IMAGENET_STD),\n",
    "])\n",
    "tx_eval = transforms.Compose([\n",
    "    transforms.Resize((224,224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(IMAGENET_MEAN, IMAGENET_STD),\n",
    "])\n",
    "\n",
    "class HFDataset(Dataset):\n",
    "    def __init__(self, split, t): self.ds, self.t = split, t\n",
    "    def __len__(self): return len(self.ds)\n",
    "    def __getitem__(self, i):\n",
    "        ex = self.ds[i]\n",
    "        img = ex[\"image\"].convert(\"RGB\")\n",
    "        x = self.t(img)\n",
    "        y = int(ex[\"label\"])\n",
    "        return x, y\n",
    "\n",
    "train_set = HFDataset(ds[\"train\"], tx_train)\n",
    "val_set   = HFDataset(ds[\"validation\"], tx_eval)\n",
    "test_set  = HFDataset(ds[\"test\"], tx_eval)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78f23c08",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30af4fb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class_counts: [1080, 3107]  class_weights: [1.938425898551941, 0.6738011240959167]\n"
     ]
    }
   ],
   "source": [
    "# 6. DataLoader\n",
    "from torch.utils.data import DataLoader\n",
    "BATCH = 64 \n",
    "\n",
    "train_loader = DataLoader(train_set, batch_size=BATCH, shuffle=True,\n",
    "                          num_workers=0, pin_memory=False)\n",
    "val_loader   = DataLoader(val_set,   batch_size=BATCH, shuffle=False,\n",
    "                          num_workers=0, pin_memory=False)\n",
    "test_loader  = DataLoader(test_set,  batch_size=BATCH, shuffle=False,\n",
    "                          num_workers=0, pin_memory=False)\n",
    "\n",
    "# class weights\n",
    "import numpy as np\n",
    "train_labels = np.array(ds[\"train\"][\"label\"], dtype=int)\n",
    "cnt = np.bincount(train_labels, minlength=2)\n",
    "class_weights = (cnt.sum()/(2.0*np.maximum(cnt,1))).astype(np.float32)\n",
    "print(\"class_counts:\", cnt.tolist(), \" class_weights:\", class_weights.tolist())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36fdf075",
   "metadata": {},
   "source": [
    "## Training Tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "9f5ee370",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model():\n",
    "    m = models.resnet18(weights=models.ResNet18_Weights.IMAGENET1K_V1)\n",
    "    m.fc = nn.Linear(m.fc.in_features, 2)\n",
    "    return m\n",
    "\n",
    "def eval_epoch(model, loader):\n",
    "    model.eval()\n",
    "    ys, p1s = [], []\n",
    "    with torch.inference_mode():\n",
    "        for x,y in loader:\n",
    "            x,y = x.to(DEVICE), y.to(DEVICE)\n",
    "            prob1 = torch.softmax(model(x), dim=1)[:,1]\n",
    "            ys.append(y.cpu().numpy()); p1s.append(prob1.cpu().numpy())\n",
    "    y_true = np.concatenate(ys); p1 = np.concatenate(p1s)\n",
    "    y_pred = (p1>=0.5).astype(int)\n",
    "    acc = accuracy_score(y_true, y_pred)\n",
    "    prec, rec, f1, _ = precision_recall_fscore_support(y_true, y_pred, average=\"binary\", zero_division=0)\n",
    "    auc = roc_auc_score(y_true, p1)\n",
    "    return {\"acc\":acc,\"prec\":prec,\"rec\":rec,\"f1\":f1,\"auc\":auc}, y_true, p1\n",
    "\n",
    "def plot_confmat_roc(y_true, p1, outdir:Path):\n",
    "    outdir = Path(outdir); outdir.mkdir(parents=True, exist_ok=True)\n",
    "    y_pred=(p1>=0.5).astype(int)\n",
    "    cm = confusion_matrix(y_true, y_pred, labels=[0,1])\n",
    "\n",
    "    fig = plt.figure(); plt.imshow(cm, interpolation='nearest')\n",
    "    plt.title(\"Confusion Matrix\"); plt.xlabel(\"Pred\"); plt.ylabel(\"True\")\n",
    "    plt.xticks([0,1],[\"normal\",\"pneumonia\"]); plt.yticks([0,1],[\"normal\",\"pneumonia\"])\n",
    "    for i in range(2):\n",
    "        for j in range(2): plt.text(j, i, cm[i,j], ha=\"center\", va=\"center\")\n",
    "    plt.tight_layout(); fig.savefig(outdir/\"confmat.png\", dpi=220); plt.close(fig)\n",
    "\n",
    "    thr = np.linspace(0,1,200); tpr=[]; fpr=[]; P=(y_true==1).sum(); N=(y_true==0).sum()\n",
    "    for t in thr:\n",
    "        yp=(p1>=t).astype(int)\n",
    "        TP=((yp==1)&(y_true==1)).sum(); FP=((yp==1)&(y_true==0)).sum()\n",
    "        TPR=TP/max(P,1); FPR=FP/max(N,1)\n",
    "        tpr.append(TPR); fpr.append(FPR)\n",
    "    fig=plt.figure(); plt.plot(fpr,tpr); plt.plot([0,1],[0,1],\"--\")\n",
    "    plt.xlabel(\"FPR\"); plt.ylabel(\"TPR\"); plt.title(\"ROC Curve\"); plt.tight_layout()\n",
    "    fig.savefig(outdir/\"roc.png\", dpi=220); plt.close(fig)\n",
    "\n",
    "def best_threshold_youden(y_true, p1):\n",
    "    thr = np.linspace(0,1,501)\n",
    "    best_t, best_j = 0.5, -1\n",
    "    for t in thr:\n",
    "        yp = (p1>=t).astype(int)\n",
    "        TP=((yp==1)&(y_true==1)).sum(); FP=((yp==1)&(y_true==0)).sum()\n",
    "        TN=((yp==0)&(y_true==0)).sum(); FN=((yp==0)&(y_true==1)).sum()\n",
    "        TPR = TP/max(TP+FN,1); FPR = FP/max(FP+TN,1)\n",
    "        J = TPR - FPR\n",
    "        if J > best_j: best_j, best_t = J, t\n",
    "    return float(best_t), float(best_j)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46bf749e",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "305bbf97",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10: 100%|██████████| 66/66 [00:43<00:00,  1.53it/s, loss=0.0530, lr=3.00e-04]\n",
      "Epoch 2/10: 100%|██████████| 66/66 [00:43<00:00,  1.52it/s, loss=0.0011, lr=3.00e-04]\n",
      "Epoch 3/10: 100%|██████████| 66/66 [00:47<00:00,  1.38it/s, loss=0.0004, lr=3.00e-04]\n",
      "Epoch 4/10: 100%|██████████| 66/66 [00:51<00:00,  1.27it/s, loss=0.0039, lr=3.00e-04]\n",
      "Epoch 5/10: 100%|██████████| 66/66 [00:49<00:00,  1.34it/s, loss=0.0008, lr=3.00e-04]\n",
      "Epoch 6/10: 100%|██████████| 66/66 [00:48<00:00,  1.36it/s, loss=0.0003, lr=1.50e-04]\n",
      "Epoch 7/10: 100%|██████████| 66/66 [00:47<00:00,  1.40it/s, loss=0.0004, lr=1.50e-04]\n",
      "Epoch 8/10: 100%|██████████| 66/66 [00:47<00:00,  1.40it/s, loss=0.0403, lr=1.50e-04]\n",
      "Epoch 9/10: 100%|██████████| 66/66 [00:47<00:00,  1.40it/s, loss=0.0020, lr=1.50e-04]\n",
      "Epoch 10/10: 100%|██████████| 66/66 [00:47<00:00,  1.39it/s, loss=0.0001, lr=1.50e-04]\n"
     ]
    }
   ],
   "source": [
    "model = build_model().to(DEVICE)\n",
    "criterion = nn.CrossEntropyLoss(weight=torch.tensor(class_weights).to(DEVICE))\n",
    "optim = torch.optim.Adam(model.parameters(), lr=3e-4, weight_decay=1e-4)\n",
    "sched = torch.optim.lr_scheduler.ReduceLROnPlateau(optim, mode=\"max\", factor=0.5, patience=2)\n",
    "\n",
    "best_f1, best_epoch, patience = -1.0, -1, 4\n",
    "history = []\n",
    "for epoch in range(1, 11):\n",
    "    model.train(); running = 0.0\n",
    "    pbar = tqdm(train_loader, desc=f\"Epoch {epoch}/10\")\n",
    "    for x,y in pbar:\n",
    "        x,y = x.to(DEVICE), y.to(DEVICE)\n",
    "        optim.zero_grad()\n",
    "        loss = criterion(model(x), y)\n",
    "        loss.backward(); optim.step()\n",
    "        running += loss.item()*x.size(0)\n",
    "        pbar.set_postfix(loss=f\"{loss.item():.4f}\", lr=f\"{optim.param_groups[0]['lr']:.2e}\")\n",
    "    tr_loss = running/len(train_loader.dataset)\n",
    "    val_metrics, _, _ = eval_epoch(model, val_loader)\n",
    "    val_f1 = float(val_metrics[\"f1\"]) if np.isfinite(val_metrics[\"f1\"]) else 0.0\n",
    "    sched.step(val_f1)\n",
    "    history.append({\"epoch\":epoch,\"train_loss\":tr_loss, **{k:float(v) for k,v in val_metrics.items()}})\n",
    "    if val_metrics[\"f1\"] > best_f1:\n",
    "        best_f1 = val_metrics[\"f1\"]; best_epoch = epoch; patience = 4\n",
    "        torch.save({\"model\":model.state_dict()}, OUT/\"best.pt\")\n",
    "    else:\n",
    "        patience -= 1\n",
    "        if patience == 0: print(\"Early stop.\"); break\n",
    "\n",
    "with open(OUT/\"history.csv\",\"w\",newline=\"\") as f:\n",
    "    w = csv.DictWriter(f, fieldnames=[\"epoch\",\"train_loss\",\"acc\",\"prec\",\"rec\",\"f1\",\"auc\"])\n",
    "    w.writeheader(); w.writerows(history)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0eb1f09a",
   "metadata": {},
   "source": [
    "## Test Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "0cd65d11",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/rk/f12c6mnd41z_j8l_3k6lnkmw0000gn/T/ipykernel_28919/1680827060.py:1: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  ckpt = torch.load(OUT/\"best.pt\", map_location=DEVICE)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved to: /Users/nolan/Desktop/507/outputs/baseline\n",
      "TEST: {'acc': 0.8589743589743589, 'prec': 0.8158995815899581, 'rec': 1.0, 'f1': 0.8986175115207373, 'auc': 0.9762382204689897}\n",
      "Best epoch: 10, Youden best threshold: 0.998 (J=0.844)\n"
     ]
    }
   ],
   "source": [
    "ckpt = torch.load(OUT/\"best.pt\", map_location=DEVICE)\n",
    "model.load_state_dict(ckpt[\"model\"])\n",
    "test_metrics, y_true, p1 = eval_epoch(model, test_loader)\n",
    "best_t, best_j = best_threshold_youden(y_true, p1)\n",
    "\n",
    "with open(OUT/\"metrics.json\",\"w\") as f:\n",
    "    json.dump({\"best_epoch\": best_epoch,\n",
    "               \"history_last\": history[-1] if history else {},\n",
    "               \"test\": {k:float(v) for k,v in test_metrics.items()},\n",
    "               \"best_threshold_youden\": best_t,\n",
    "               \"best_J\": best_j}, f, indent=2)\n",
    "\n",
    "plot_confmat_roc(y_true, p1, OUT)\n",
    "print(\"Saved to:\", OUT.resolve())\n",
    "print(\"TEST:\", test_metrics)\n",
    "print(f\"Best epoch: {best_epoch}, Youden best threshold: {best_t:.3f} (J={best_j:.3f})\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11deac18",
   "metadata": {},
   "source": [
    "## 增强 tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72195f9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# augmentation tool\n",
    "from torchvision import transforms\n",
    "\n",
    "IMAGENET_MEAN=[0.485,0.456,0.406]; IMAGENET_STD=[0.229,0.224,0.225]\n",
    "\n",
    "def get_transform(level):\n",
    "    if level==\"light\":\n",
    "        return transforms.Compose([\n",
    "            transforms.Resize((224,224)),\n",
    "            transforms.RandomHorizontalFlip(p=0.5),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(IMAGENET_MEAN, IMAGENET_STD),\n",
    "        ])\n",
    "    if level==\"medium\":\n",
    "        return transforms.Compose([\n",
    "            transforms.Resize((224,224)),\n",
    "            transforms.RandomResizedCrop(224, scale=(0.9,1.0)),\n",
    "            transforms.RandomHorizontalFlip(p=0.5),\n",
    "            transforms.RandomRotation(degrees=10),\n",
    "            transforms.ColorJitter(brightness=0.1, contrast=0.1),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(IMAGENET_MEAN, IMAGENET_STD),\n",
    "        ])\n",
    "    if level==\"strong\":\n",
    "        return transforms.Compose([\n",
    "            transforms.Resize((224,224)),\n",
    "            transforms.RandomResizedCrop(224, scale=(0.8,1.0)),\n",
    "            transforms.RandomHorizontalFlip(p=0.5),\n",
    "            transforms.RandomRotation(degrees=15),\n",
    "            transforms.ColorJitter(brightness=0.2, contrast=0.2),\n",
    "            transforms.ToTensor(),                                  \n",
    "            transforms.RandomErasing(p=0.5, scale=(0.02,0.1), ratio=(0.3,3.3)),  \n",
    "            transforms.GaussianBlur(kernel_size=3, sigma=(0.1,1.0)),\n",
    "            transforms.Normalize(IMAGENET_MEAN, IMAGENET_STD),\n",
    "        ])\n",
    "    raise ValueError(level)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef15802b",
   "metadata": {},
   "source": [
    "## 增强结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b987af2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Augmentation: light -> outputs/aug_light ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[light] Epoch 1/10: 100%|██████████| 66/66 [00:42<00:00,  1.56it/s, loss=0.1374]\n",
      "[light] Epoch 2/10: 100%|██████████| 66/66 [00:43<00:00,  1.50it/s, loss=0.0090]\n",
      "[light] Epoch 3/10: 100%|██████████| 66/66 [00:42<00:00,  1.54it/s, loss=0.0735]\n",
      "[light] Epoch 4/10: 100%|██████████| 66/66 [00:43<00:00,  1.52it/s, loss=0.0370]\n",
      "[light] Epoch 5/10: 100%|██████████| 66/66 [00:44<00:00,  1.48it/s, loss=0.0010]\n",
      "[light] Epoch 6/10: 100%|██████████| 66/66 [00:47<00:00,  1.38it/s, loss=0.0026]\n",
      "[light] Epoch 7/10: 100%|██████████| 66/66 [00:47<00:00,  1.40it/s, loss=0.0001]\n",
      "[light] Epoch 8/10: 100%|██████████| 66/66 [00:48<00:00,  1.37it/s, loss=0.0002]\n",
      "[light] Epoch 9/10: 100%|██████████| 66/66 [00:47<00:00,  1.39it/s, loss=0.0009]\n",
      "[light] Epoch 10/10: 100%|██████████| 66/66 [00:47<00:00,  1.38it/s, loss=0.0004]\n",
      "/var/folders/rk/f12c6mnd41z_j8l_3k6lnkmw0000gn/T/ipykernel_28919/4086328189.py:60: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  ckpt = torch.load(out/\"best.pt\", map_location=DEVICE)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[light] TEST: {'acc': 0.8685897435897436, 'prec': 0.826271186440678, 'rec': 1.0, 'f1': 0.9048723897911833, 'auc': 0.9750438308130617}\n",
      "\n",
      "=== Augmentation: medium -> outputs/aug_medium ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[medium] Epoch 1/10: 100%|██████████| 66/66 [00:51<00:00,  1.29it/s, loss=0.5562]\n",
      "[medium] Epoch 2/10: 100%|██████████| 66/66 [00:51<00:00,  1.28it/s, loss=0.0059]\n",
      "[medium] Epoch 3/10: 100%|██████████| 66/66 [00:51<00:00,  1.28it/s, loss=0.0096]\n",
      "[medium] Epoch 4/10: 100%|██████████| 66/66 [00:54<00:00,  1.21it/s, loss=0.0129]\n",
      "[medium] Epoch 5/10: 100%|██████████| 66/66 [00:54<00:00,  1.21it/s, loss=0.0422]\n",
      "[medium] Epoch 6/10: 100%|██████████| 66/66 [00:53<00:00,  1.22it/s, loss=0.0055]\n",
      "[medium] Epoch 7/10: 100%|██████████| 66/66 [00:54<00:00,  1.20it/s, loss=0.0434]\n",
      "[medium] Epoch 8/10: 100%|██████████| 66/66 [00:54<00:00,  1.21it/s, loss=0.0192]\n",
      "[medium] Epoch 9/10: 100%|██████████| 66/66 [00:52<00:00,  1.25it/s, loss=0.0715]\n",
      "[medium] Epoch 10/10: 100%|██████████| 66/66 [00:55<00:00,  1.19it/s, loss=0.1127]\n",
      "/var/folders/rk/f12c6mnd41z_j8l_3k6lnkmw0000gn/T/ipykernel_28919/4086328189.py:60: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  ckpt = torch.load(out/\"best.pt\", map_location=DEVICE)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[medium] TEST: {'acc': 0.9310897435897436, 'prec': 0.9044289044289044, 'rec': 0.9948717948717949, 'f1': 0.9474969474969475, 'auc': 0.9928884505807583}\n",
      "\n",
      "=== Augmentation: strong -> outputs/aug_strong ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[strong] Epoch 1/10: 100%|██████████| 66/66 [00:58<00:00,  1.13it/s, loss=0.0569]\n",
      "[strong] Epoch 2/10: 100%|██████████| 66/66 [00:57<00:00,  1.15it/s, loss=0.0156]\n",
      "[strong] Epoch 3/10: 100%|██████████| 66/66 [00:58<00:00,  1.13it/s, loss=0.1349]\n",
      "[strong] Epoch 4/10: 100%|██████████| 66/66 [00:57<00:00,  1.16it/s, loss=0.1235]\n",
      "[strong] Epoch 5/10: 100%|██████████| 66/66 [00:57<00:00,  1.16it/s, loss=0.0924]\n",
      "/var/folders/rk/f12c6mnd41z_j8l_3k6lnkmw0000gn/T/ipykernel_28919/4086328189.py:60: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  ckpt = torch.load(out/\"best.pt\", map_location=DEVICE)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[strong] TEST: {'acc': 0.9326923076923077, 'prec': 0.910377358490566, 'rec': 0.9897435897435898, 'f1': 0.9484029484029484, 'auc': 0.9894915625684857}\n",
      "Saved summary -> /Users/nolan/Desktop/507/outputs/aug_summary.csv\n"
     ]
    }
   ],
   "source": [
    "import json, csv, numpy as np, torch, torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "\n",
    "OUT_ROOT = Path(\"outputs\")\n",
    "TX_EVAL = transforms.Compose([\n",
    "    transforms.Resize((224,224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(IMAGENET_MEAN, IMAGENET_STD),\n",
    "])\n",
    "\n",
    "train_labels = np.array(ds[\"train\"][\"label\"], dtype=int)\n",
    "cnt = np.bincount(train_labels, minlength=2)\n",
    "class_weights = (cnt.sum()/(2.0*np.maximum(cnt,1))).astype(np.float32)\n",
    "\n",
    "def run_one_augmentation(level):\n",
    "    out = OUT_ROOT/f\"aug_{level}\"\n",
    "    out.mkdir(parents=True, exist_ok=True)\n",
    "    print(f\"\\n=== Augmentation: {level} -> {out} ===\")\n",
    "\n",
    "    train_set = HFDataset(ds[\"train\"], get_transform(level))\n",
    "    val_set   = HFDataset(ds[\"validation\"], TX_EVAL)\n",
    "    test_set  = HFDataset(ds[\"test\"], TX_EVAL)\n",
    "\n",
    "    train_loader = DataLoader(train_set, batch_size=64, shuffle=True,  num_workers=0, pin_memory=False)\n",
    "    val_loader   = DataLoader(val_set,   batch_size=64, shuffle=False, num_workers=0, pin_memory=False)\n",
    "    test_loader  = DataLoader(test_set,  batch_size=64, shuffle=False, num_workers=0, pin_memory=False)\n",
    "\n",
    "    model = build_model().to(DEVICE)\n",
    "    criterion = nn.CrossEntropyLoss(weight=torch.tensor(class_weights).to(DEVICE))\n",
    "    optim = torch.optim.Adam(model.parameters(), lr=3e-4, weight_decay=1e-4)\n",
    "    sched = torch.optim.lr_scheduler.ReduceLROnPlateau(optim, mode=\"max\", factor=0.5, patience=2)\n",
    "\n",
    "    best_f1, patience, history = -1.0, 4, []\n",
    "    for epoch in range(1, 11):\n",
    "        model.train(); running=0.0\n",
    "        pbar = tqdm(train_loader, desc=f\"[{level}] Epoch {epoch}/10\")\n",
    "        for x,y in pbar:\n",
    "            x,y = x.to(DEVICE), y.to(DEVICE)\n",
    "            optim.zero_grad()\n",
    "            loss = criterion(model(x), y)\n",
    "            loss.backward(); optim.step()\n",
    "            running += loss.item()*x.size(0)\n",
    "            pbar.set_postfix(loss=f\"{loss.item():.4f}\")\n",
    "        tr_loss = running/len(train_loader.dataset)\n",
    "        val_metrics, _, _ = eval_epoch(model, val_loader)\n",
    "        sched.step(float(val_metrics[\"f1\"]))\n",
    "        history.append({\"epoch\":epoch,\"train_loss\":tr_loss, **{k:float(v) for k,v in val_metrics.items()}})\n",
    "        if val_metrics[\"f1\"] > best_f1:\n",
    "            best_f1 = val_metrics[\"f1\"]; patience = 4\n",
    "            torch.save({\"model\":model.state_dict()}, out/\"best.pt\")\n",
    "        else:\n",
    "            patience -= 1\n",
    "            if patience == 0: break\n",
    "\n",
    "    ckpt = torch.load(out/\"best.pt\", map_location=DEVICE)\n",
    "    model.load_state_dict(ckpt[\"model\"])\n",
    "    test_metrics, y_true, p1 = eval_epoch(model, test_loader)\n",
    "    with open(out/\"metrics.json\",\"w\") as f:\n",
    "        json.dump({\"history\":history, \"test\":{k:float(v) for k,v in test_metrics.items()}}, f, indent=2)\n",
    "    plot_confmat_roc(y_true, p1, out)\n",
    "    print(f\"[{level}] TEST:\", test_metrics)\n",
    "    return level, test_metrics\n",
    "\n",
    "results = []\n",
    "for lv in [\"light\",\"medium\",\"strong\"]:\n",
    "    name, m = run_one_augmentation(lv)\n",
    "    results.append([name, m[\"acc\"], m[\"prec\"], m[\"rec\"], m[\"f1\"], m[\"auc\"]])\n",
    "\n",
    "OUT_ROOT.mkdir(parents=True, exist_ok=True)\n",
    "with open(OUT_ROOT/\"aug_summary.csv\",\"w\",newline=\"\") as f:\n",
    "    w = csv.writer(f)\n",
    "    w.writerow([\"augmentation\",\"accuracy\",\"precision\",\"recall\",\"f1\",\"auc\"])\n",
    "    w.writerows(results)\n",
    "\n",
    "print(\"Saved summary ->\", (OUT_ROOT/\"aug_summary.csv\").resolve())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "660b7d1e",
   "metadata": {},
   "source": [
    "## VIT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf2e9f56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on Device: mps\n",
      ">>> 1. Loading Dataset...\n",
      ">>> Class Weights: [1.9384259 0.6738011] (Counts: [1080 3107])\n",
      ">>> Start Training (5 Epochs)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/5:   0%|          | 0/131 [00:58<?, ?it/s]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "view size is not compatible with input tensor's size and stride (at least one dimension spans across two contiguous subspaces). Use .reshape(...) instead.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 218\u001b[0m\n\u001b[1;32m    215\u001b[0m logits \u001b[38;5;241m=\u001b[39m model(x)\n\u001b[1;32m    216\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(logits, y)\n\u001b[0;32m--> 218\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[1;32m    219\u001b[0m optim\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m    221\u001b[0m run_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem() \u001b[38;5;241m*\u001b[39m x\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/torch/_tensor.py:581\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    571\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    572\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    573\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    574\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    579\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    580\u001b[0m     )\n\u001b[0;32m--> 581\u001b[0m torch\u001b[38;5;241m.\u001b[39mautograd\u001b[38;5;241m.\u001b[39mbackward(\n\u001b[1;32m    582\u001b[0m     \u001b[38;5;28mself\u001b[39m, gradient, retain_graph, create_graph, inputs\u001b[38;5;241m=\u001b[39minputs\n\u001b[1;32m    583\u001b[0m )\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/torch/autograd/__init__.py:347\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    342\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    344\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    345\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    346\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 347\u001b[0m _engine_run_backward(\n\u001b[1;32m    348\u001b[0m     tensors,\n\u001b[1;32m    349\u001b[0m     grad_tensors_,\n\u001b[1;32m    350\u001b[0m     retain_graph,\n\u001b[1;32m    351\u001b[0m     create_graph,\n\u001b[1;32m    352\u001b[0m     inputs,\n\u001b[1;32m    353\u001b[0m     allow_unreachable\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    354\u001b[0m     accumulate_grad\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    355\u001b[0m )\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/torch/autograd/graph.py:825\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    823\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[1;32m    824\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 825\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m Variable\u001b[38;5;241m.\u001b[39m_execution_engine\u001b[38;5;241m.\u001b[39mrun_backward(  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[1;32m    826\u001b[0m         t_outputs, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[1;32m    827\u001b[0m     )  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[1;32m    828\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    829\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[0;31mRuntimeError\u001b[0m: view size is not compatible with input tensor's size and stride (at least one dimension spans across two contiguous subspaces). Use .reshape(...) instead."
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "from datasets import load_dataset\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from torchvision.models import vit_b_16, ViT_B_16_Weights\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support, roc_auc_score, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "SEED = 114514\n",
    "def set_seed(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "set_seed(SEED)\n",
    "\n",
    "os.environ[\"PYTORCH_ENABLE_MPS_FALLBACK\"] = \"1\"\n",
    "\n",
    "DEVICE = (\"mps\" if torch.backends.mps.is_available() \n",
    "          else \"cuda\" if torch.cuda.is_available() \n",
    "          else \"cpu\")\n",
    "print(f\"Running on Device: {DEVICE}\")\n",
    "\n",
    "OUT = Path(\"outputs/vit_fix\")\n",
    "OUT.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "IMAGENET_MEAN = [0.485, 0.456, 0.406]\n",
    "IMAGENET_STD  = [0.229, 0.224, 0.225]\n",
    "\n",
    "def to_rgb(img):\n",
    "    return img.convert(\"RGB\")\n",
    "\n",
    "tx_train = transforms.Compose([\n",
    "    transforms.Lambda(to_rgb),\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.RandomHorizontalFlip(0.5),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(IMAGENET_MEAN, IMAGENET_STD),\n",
    "])\n",
    "\n",
    "tx_eval = transforms.Compose([\n",
    "    transforms.Lambda(to_rgb),\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(IMAGENET_MEAN, IMAGENET_STD),\n",
    "])\n",
    "\n",
    "class HFDataset(Dataset):\n",
    "    def __init__(self, split, t):\n",
    "        self.ds = split\n",
    "        self.t = t\n",
    "    def __len__(self): \n",
    "        return len(self.ds)\n",
    "    def __getitem__(self, i):\n",
    "        item = self.ds[i]     \n",
    "        x = self.t(item[\"image\"])\n",
    "        y = int(item[\"label\"])\n",
    "        return x, y\n",
    "\n",
    "def build_model():\n",
    "    m = vit_b_16(weights=ViT_B_16_Weights.IMAGENET1K_V1)\n",
    "    in_f = m.heads.head.in_features\n",
    "    m.heads.head = nn.Linear(in_f, 2)\n",
    "    return m\n",
    "\n",
    "@torch.no_grad()\n",
    "def eval_epoch(model, loader):\n",
    "    model.eval()\n",
    "    ys, p1s = [], []\n",
    "    for x, y in loader:\n",
    "        x = x.to(DEVICE)\n",
    "        if not x.is_contiguous(): x = x.contiguous()\n",
    "        y = y.to(DEVICE)\n",
    "        \n",
    "        logits = model(x)\n",
    "        prob1 = torch.softmax(logits, dim=1)[:, 1]\n",
    "        \n",
    "        ys.append(y.cpu().numpy())\n",
    "        p1s.append(prob1.cpu().numpy())\n",
    "\n",
    "    if not ys: return {}, np.array([]), np.array([]) \n",
    "\n",
    "    y_true = np.concatenate(ys)\n",
    "    p1 = np.concatenate(p1s)\n",
    "    y_pred = (p1 >= 0.5).astype(int)\n",
    "    \n",
    "    acc = accuracy_score(y_true, y_pred)\n",
    "    prec, rec, f1, _ = precision_recall_fscore_support(y_true, y_pred, average=\"binary\", zero_division=0)\n",
    "    try:\n",
    "        auc = roc_auc_score(y_true, p1)\n",
    "    except:\n",
    "        auc = 0.5\n",
    "\n",
    "    return {\"acc\": acc, \"prec\": prec, \"rec\": rec, \"f1\": f1, \"auc\": auc}, y_true, p1\n",
    "\n",
    "def plot_results(y_true, p1, outdir):\n",
    "    if len(y_true) == 0: return\n",
    "    y_pred = (p1 >= 0.5).astype(int)\n",
    "    \n",
    "    cm = confusion_matrix(y_true, y_pred, labels=[0,1])\n",
    "    fig = plt.figure()\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)\n",
    "    plt.title(\"Confusion Matrix\")\n",
    "    plt.xticks([0,1], [\"Normal\", \"Pneumonia\"])\n",
    "    plt.yticks([0,1], [\"Normal\", \"Pneumonia\"])\n",
    "    for i in range(2):\n",
    "        for j in range(2):\n",
    "            plt.text(j, i, cm[i,j], ha=\"center\", va=\"center\", color=\"red\")\n",
    "    plt.tight_layout()\n",
    "    fig.savefig(outdir/\"confmat.png\")\n",
    "    plt.close()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    print(\">>> 1. Loading Dataset...\")\n",
    "\n",
    "    try:\n",
    "        raw_ds = load_dataset(\"mmenendezg/pneumonia_x_ray\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading dataset: {e}\")\n",
    "        exit(1)\n",
    "\n",
    "    if \"validation\" not in raw_ds:\n",
    "        print(\"   Warning: No validation set found. Splitting from train...\")\n",
    "        split = raw_ds[\"train\"].train_test_split(test_size=0.1, seed=SEED)\n",
    "        ds = {\"train\": split[\"train\"], \"validation\": split[\"test\"], \"test\": raw_ds.get(\"test\", split[\"test\"])}\n",
    "    else:\n",
    "        ds = raw_ds\n",
    "\n",
    "    train_set = HFDataset(ds[\"train\"], tx_train)\n",
    "    val_set   = HFDataset(ds[\"validation\"], tx_eval)\n",
    "    test_set  = HFDataset(ds[\"test\"], tx_eval)\n",
    "\n",
    "    BATCH = 32\n",
    "    train_loader = DataLoader(train_set, batch_size=BATCH, shuffle=True, num_workers=0)\n",
    "    val_loader   = DataLoader(val_set, batch_size=BATCH, shuffle=False, num_workers=0)\n",
    "    test_loader  = DataLoader(test_set, batch_size=BATCH, shuffle=False, num_workers=0)\n",
    "\n",
    "    try:\n",
    "        labels_list = ds[\"train\"][\"label\"]\n",
    "    except:\n",
    "        labels_list = [x['label'] for x in ds[\"train\"]]\n",
    "        \n",
    "    cnt = np.bincount(labels_list, minlength=2)\n",
    "    cw = (cnt.sum() / (2.0 * np.maximum(cnt, 1))).astype(np.float32)\n",
    "    cw_t = torch.tensor(cw, dtype=torch.float32).to(DEVICE)\n",
    "    print(f\">>> Class Weights: {cw} (Counts: {cnt})\")\n",
    "\n",
    "    model = build_model().to(DEVICE)\n",
    "    model = model.to(memory_format=torch.contiguous_format)\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss(weight=cw_t)\n",
    "    optim = torch.optim.AdamW(model.parameters(), lr=1e-4, weight_decay=0.01)\n",
    "    sched = torch.optim.lr_scheduler.ReduceLROnPlateau(optim, mode=\"max\", factor=0.5, patience=1)\n",
    "\n",
    "    EPOCHS = 5\n",
    "    best_f1 = -1.0\n",
    "    \n",
    "    print(f\">>> Start Training ({EPOCHS} Epochs)...\")\n",
    "    \n",
    "    if DEVICE == \"mps\":\n",
    "        dummy = torch.randn(2, 3, 224, 224).to(DEVICE)\n",
    "        _ = model(dummy)\n",
    "\n",
    "    for epoch in range(1, EPOCHS+1):\n",
    "        model.train()\n",
    "        run_loss = 0.0\n",
    "        pbar = tqdm(train_loader, desc=f\"Epoch {epoch}/{EPOCHS}\")\n",
    "        \n",
    "        for x, y in pbar:\n",
    "            x = x.to(DEVICE, non_blocking=True)\n",
    "            if not x.is_contiguous():\n",
    "                x = x.contiguous()\n",
    "            \n",
    "            y = y.to(DEVICE).long()\n",
    "            \n",
    "            optim.zero_grad(set_to_none=True)\n",
    "            \n",
    "            logits = model(x)\n",
    "            loss = criterion(logits, y)\n",
    "            \n",
    "            loss.backward()\n",
    "            optim.step()\n",
    "            \n",
    "            run_loss += loss.item() * x.size(0)\n",
    "            pbar.set_postfix(loss=f\"{loss.item():.4f}\")\n",
    "\n",
    "        avg_loss = run_loss / len(train_set)\n",
    "        val_m, _, _ = eval_epoch(model, val_loader)\n",
    "        \n",
    "        print(f\"   [Val] Loss: {avg_loss:.4f} | F1: {val_m['f1']:.4f} | Acc: {val_m['acc']:.4f}\")\n",
    "        \n",
    "        sched.step(val_m[\"f1\"])\n",
    "        \n",
    "        if val_m[\"f1\"] > best_f1:\n",
    "            best_f1 = val_m[\"f1\"]\n",
    "            torch.save({\"model\": model.state_dict()}, OUT/\"best.pt\")\n",
    "            print(\"   >>> Best Model Saved!\")\n",
    "            \n",
    "    # test\n",
    "    print(\"\\n>>> Testing Best Model...\")\n",
    "    ckpt = torch.load(OUT/\"best.pt\", map_location=DEVICE)\n",
    "    model.load_state_dict(ckpt[\"model\"])\n",
    "    test_m, y_true, p1 = eval_epoch(model, test_loader)\n",
    "    \n",
    "    plot_results(y_true, p1, OUT)\n",
    "    \n",
    "    with open(OUT/\"metrics.json\", \"w\") as f:\n",
    "        json.dump(test_m, f, indent=4)\n",
    "        \n",
    "    print(f\"Final Test Metrics: {test_m}\")\n",
    "    print(f\"Results saved to: {OUT.resolve()}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
